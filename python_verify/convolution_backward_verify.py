import numpy as np

def im2col(input_data, kernel_size, stride=1, padding=1):
    """
    å°†è¾“å…¥æ•°æ®è½¬æ¢ä¸ºåˆ—çŸ©é˜µå½¢å¼ï¼Œç”¨äºå·ç§¯è¿ç®—
    """
    batch_size, channels, height, width = input_data.shape
    out_height = (height + 2 * padding - kernel_size) // stride + 1
    out_width = (width + 2 * padding - kernel_size) // stride + 1
    
    # æ·»åŠ padding
    padded_input = np.pad(input_data, ((0, 0), (0, 0), (padding, padding), (padding, padding)), 'constant')
    
    # åˆ›å»ºè¾“å‡ºçŸ©é˜µ
    col_matrix = np.zeros((batch_size, channels * kernel_size * kernel_size, out_height * out_width))
    
    for i in range(out_height):
        for j in range(out_width):
            h_start = i * stride
            h_end = h_start + kernel_size
            w_start = j * stride
            w_end = w_start + kernel_size
            
            # æå–å½“å‰çª—å£çš„æ•°æ®
            window = padded_input[:, :, h_start:h_end, w_start:w_end]
            # å±•å¹³å¹¶å­˜å‚¨
            col_matrix[:, :, i * out_width + j] = window.reshape(batch_size, -1)
    
    return col_matrix

def col2im(col_matrix, input_shape, kernel_size, stride=1, padding=1):
    """
    å°†åˆ—çŸ©é˜µè½¬æ¢å›å›¾åƒå½¢å¼ï¼Œç”¨äºåå‘ä¼ æ’­
    """
    batch_size, channels, height, width = input_shape
    out_height = (height + 2 * padding - kernel_size) // stride + 1
    out_width = (width + 2 * padding - kernel_size) // stride + 1
    
    # åˆ›å»ºå¸¦paddingçš„è¾“å…¥æ¢¯åº¦
    padded_grad = np.zeros((batch_size, channels, height + 2 * padding, width + 2 * padding))
    
    for i in range(out_height):
        for j in range(out_width):
            h_start = i * stride
            h_end = h_start + kernel_size
            w_start = j * stride
            w_end = w_start + kernel_size
            
            # è·å–å½“å‰ä½ç½®çš„æ¢¯åº¦
            grad_window = col_matrix[:, :, i * out_width + j].reshape(batch_size, channels, kernel_size, kernel_size)
            # ç´¯åŠ åˆ°å¯¹åº”ä½ç½®
            padded_grad[:, :, h_start:h_end, w_start:w_end] += grad_window
    
    # ç§»é™¤padding
    if padding > 0:
        grad_input = padded_grad[:, :, padding:-padding, padding:-padding]
    else:
        grad_input = padded_grad
    
    return grad_input

def convolution_backward_verify():
    """
    éªŒè¯å·ç§¯å±‚åå‘ä¼ æ’­ï¼Œä½¿ç”¨ä¸Goæµ‹è¯•ç›¸åŒçš„æ•°æ®
    """
    print("=== å·ç§¯å±‚åå‘ä¼ æ’­éªŒè¯ ===\n")
    
    # è®¾ç½®å‚æ•°ï¼ˆä¸Goæµ‹è¯•ç›¸åŒï¼‰
    batch_size = 1
    in_channels = 1
    out_channels = 1
    kernel_size = 3
    stride = 1
    padding = 1
    input_height = 3
    input_width = 3
    
    # è¾“å…¥æ•°æ®ï¼š[1, 2, 3, 4, 5, 6, 7, 8, 9]
    input_data = np.array([[[[1, 2, 3],
                             [4, 5, 6],
                             [7, 8, 9]]]], dtype=np.float32)  # (1, 1, 3, 3)
    
    # æƒé‡ï¼š[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]
    weights = np.array([[[[0.0, 0.1, 0.2],
                          [0.3, 0.4, 0.5],
                          [0.6, 0.7, 0.8]]]], dtype=np.float32)  # (1, 1, 3, 3)
    
    # åç½®ï¼š[0.0]
    biases = np.array([0.0], dtype=np.float32)
    
    # æ¢¯åº¦è¾“å‡ºï¼šå…¨1çŸ©é˜µ
    grad_output = np.ones((batch_size, out_channels, input_height, input_width), dtype=np.float32)
    
    print("è¾“å…¥çŸ©é˜µ (1x9):")
    print(input_data.flatten())
    print()
    
    print("åˆå§‹æƒé‡çŸ©é˜µ (1x9):")
    print(weights.flatten())
    print()
    
    print("åˆå§‹åç½®çŸ©é˜µ (1x1):")
    print(biases)
    print()
    
    print("æ¢¯åº¦è¾“å‡ºçŸ©é˜µ (1x9):")
    print(grad_output.flatten())
    print()
    
    # å‰å‘ä¼ æ’­ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
    # æ·»åŠ padding
    padded_input = np.pad(input_data, ((0, 0), (0, 0), (padding, padding), (padding, padding)), 'constant')
    
    # æ‰‹åŠ¨è®¡ç®—å·ç§¯è¾“å‡º
    output = np.zeros((batch_size, out_channels, input_height, input_width))
    
    for i in range(input_height):
        for j in range(input_width):
            h_start = i
            h_end = h_start + kernel_size
            w_start = j
            w_end = w_start + kernel_size
            
            # æå–è¾“å…¥çª—å£
            input_window = padded_input[0, 0, h_start:h_end, w_start:w_end]
            # å·ç§¯è¿ç®—
            output[0, 0, i, j] = np.sum(input_window * weights[0, 0]) + biases[0]
    
    print("å‰å‘ä¼ æ’­è¾“å‡º (1x9):")
    print(output.flatten())
    print()
    
    # åå‘ä¼ æ’­
    # 1. è®¡ç®—åç½®æ¢¯åº¦ï¼šæ‰€æœ‰è¾“å‡ºä½ç½®çš„æ¢¯åº¦ä¹‹å’Œ
    grad_bias = np.sum(grad_output)
    
    # 2. è®¡ç®—æƒé‡æ¢¯åº¦ï¼šè¾“å…¥çª—å£ä¸è¾“å‡ºæ¢¯åº¦çš„å¤–ç§¯
    grad_weights = np.zeros_like(weights[0, 0])
    
    for i in range(input_height):
        for j in range(input_width):
            h_start = i
            h_end = h_start + kernel_size
            w_start = j
            w_end = w_start + kernel_size
            
            # æå–è¾“å…¥çª—å£
            input_window = padded_input[0, 0, h_start:h_end, w_start:w_end]
            # æƒé‡æ¢¯åº¦ç´¯åŠ 
            grad_weights += input_window * grad_output[0, 0, i, j]
    
    # 3. è®¡ç®—è¾“å…¥æ¢¯åº¦ï¼šæƒé‡ä¸è¾“å‡ºæ¢¯åº¦çš„å·ç§¯
    grad_input = np.zeros_like(input_data[0, 0])
    
    # åˆ›å»ºå¸¦paddingçš„æ¢¯åº¦è¾“å‡º
    padded_grad_output = np.pad(grad_output[0, 0], ((padding, padding), (padding, padding)), 'constant')
    
    # ç¿»è½¬æƒé‡ï¼ˆå·ç§¯çš„è½¬ç½®æ“ä½œï¼‰
    flipped_weights = np.flip(weights[0, 0])
    
    for i in range(input_height):
        for j in range(input_width):
            h_start = i
            h_end = h_start + kernel_size
            w_start = j
            w_end = w_start + kernel_size
            
            # æå–æ¢¯åº¦è¾“å‡ºçª—å£
            grad_window = padded_grad_output[h_start:h_end, w_start:w_end]
            # è¾“å…¥æ¢¯åº¦ç´¯åŠ 
            grad_input[i, j] = np.sum(grad_window * flipped_weights)
    
    print("=== åå‘ä¼ æ’­ç»“æœ ===")
    print()
    
    print("è¾“å…¥æ¢¯åº¦çŸ©é˜µ (1x9):")
    print(grad_input.flatten())
    print()
    
    print("æƒé‡æ¢¯åº¦çŸ©é˜µ (1x9):")
    print(grad_weights.flatten())
    print()
    
    print("åç½®æ¢¯åº¦çŸ©é˜µ (1x1):")
    print(np.array([grad_bias]))
    print()
    
    # ä¸Goæµ‹è¯•ç»“æœå¯¹æ¯”
    print("=== ä¸Goæµ‹è¯•ç»“æœå¯¹æ¯” ===")
    print()
    
    go_input_grad = np.array([0.8, 1.5, 1.2, 2.1, 3.6, 2.7, 2.0, 3.3, 2.4])
    go_weight_grad = np.array([12.0, 21.0, 16.0, 27.0, 45.0, 33.0, 24.0, 39.0, 28.0])
    go_bias_grad = np.array([9.0])
    
    print("Pythonè¾“å…¥æ¢¯åº¦:", grad_input.flatten())
    print("Goè¾“å…¥æ¢¯åº¦:    ", go_input_grad)
    print("è¾“å…¥æ¢¯åº¦å·®å¼‚:   ", np.abs(grad_input.flatten() - go_input_grad))
    print()
    
    print("Pythonæƒé‡æ¢¯åº¦:", grad_weights.flatten())
    print("Goæƒé‡æ¢¯åº¦:    ", go_weight_grad)
    print("æƒé‡æ¢¯åº¦å·®å¼‚:   ", np.abs(grad_weights.flatten() - go_weight_grad))
    print()
    
    print("Pythonåç½®æ¢¯åº¦:", np.array([grad_bias]))
    print("Goåç½®æ¢¯åº¦:    ", go_bias_grad)
    print("åç½®æ¢¯åº¦å·®å¼‚:   ", np.abs(np.array([grad_bias]) - go_bias_grad))
    print()
    
    # æ£€æŸ¥æ˜¯å¦åŒ¹é…
    input_match = np.allclose(grad_input.flatten(), go_input_grad, atol=1e-6)
    weight_match = np.allclose(grad_weights.flatten(), go_weight_grad, atol=1e-6)
    bias_match = np.allclose(np.array([grad_bias]), go_bias_grad, atol=1e-6)
    
    print("=== éªŒè¯ç»“æœ ===")
    print(f"è¾“å…¥æ¢¯åº¦åŒ¹é…: {'âœ…' if input_match else 'âŒ'}")
    print(f"æƒé‡æ¢¯åº¦åŒ¹é…: {'âœ…' if weight_match else 'âŒ'}")
    print(f"åç½®æ¢¯åº¦åŒ¹é…: {'âœ…' if bias_match else 'âŒ'}")
    
    if input_match and weight_match and bias_match:
        print("\nğŸ‰ æ‰€æœ‰æ¢¯åº¦è®¡ç®—éƒ½åŒ¹é…Goå®ç°ï¼")
    else:
        print("\nâš ï¸  å­˜åœ¨ä¸åŒ¹é…çš„æ¢¯åº¦è®¡ç®—")

if __name__ == "__main__":
    convolution_backward_verify() 